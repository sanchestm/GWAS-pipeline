{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a210526a-f623-431f-8fe4-5cefd034ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip\n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm\n",
    "#from tqdm.auto import tqdm\n",
    "import gc\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "from pathlib import Path\n",
    "import os\n",
    "import inspect\n",
    "from time import sleep\n",
    "import sys\n",
    "import itertools\n",
    "from IPython.utils import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c529728-de67-4316-b13c-567ee078ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class vcftools:\n",
    "    def corrfunc(x, y, ax=None, **kws):\n",
    "        r, _ = pearsonr(x, y)\n",
    "        ax = ax or plt.gca()\n",
    "        ax.annotate(f'Ï = {r:.2f}', xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "    def get_vcf_header(vcf_path):\n",
    "        with gzip.open(vcf_path, \"rt\") as ifile:\n",
    "            for num, line in enumerate(ifile):\n",
    "                if line.startswith(\"#CHROM\"): return line.strip().split('\\t')\n",
    "                if num > 10000: return '-1'\n",
    "        return '-1'\n",
    "\n",
    "    def read_vcf(filename, method = 'pandas'):\n",
    "        if method == 'dask':\n",
    "            return dd.read_csv(filename,  compression='gzip', comment='#',  delim_whitespace=True, header=None, \n",
    "                               names = vcftools.get_vcf_header(filename),blocksize=None,  dtype=str, ).repartition(npartitions = 100000)\n",
    "        # usecols=['#CHROM', 'POS']\n",
    "        return pd.read_csv(filename,  compression='gzip', comment='#',  delim_whitespace=True,\n",
    "                           header=None, names = vcftools.get_vcf_header(filename),  dtype=str )\n",
    "\n",
    "    def name_gen2(filename):\n",
    "        return filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    def get_vcf_metadata(vcf_path):\n",
    "        out = ''\n",
    "        with gzip.open(vcf_path, \"rt\") as ifile:\n",
    "            for num, line in enumerate(ifile):\n",
    "                if line.startswith(\"#CHROM\"): return out\n",
    "                out += line \n",
    "        return '-1'\n",
    "\n",
    "    def pandas2vcf(df, filename, metadata = ''):\n",
    "        if not metadata:\n",
    "            header = \"\"\"##fileformat=VCFv4.1\n",
    "            ##fileDate=20090805\n",
    "            ##source=myImputationProgramV3.1\n",
    "            ##reference=file:///seq/references/\n",
    "            \"\"\"\n",
    "        if metadata[-4:] == '.vcf': get_vcf_metadata(metadata)\n",
    "        else: header = metadata\n",
    "        with open(filename, 'w') as vcf: vcf.write(header)\n",
    "        df.to_csv(filename, sep=\"\\t\", mode='a', index=False)\n",
    "\n",
    "    def get_vcf_header(vcf_path):\n",
    "        with gzip.open(vcf_path, \"rt\") as ifile:\n",
    "            for num, line in enumerate(ifile):\n",
    "                if line.startswith(\"#CHROM\"): return line.strip().split('\\t')\n",
    "                if num > 10000: return '-1'\n",
    "        return '-1'\n",
    "\n",
    "\n",
    "def bash(call, verbose = 0, return_stdout = True, print_call = True):\n",
    "    if print_call: print(call+'\\n')\n",
    "    out = subprocess.run(call.split(' '), capture_output = True) \n",
    "    if verbose and not return_stdout: print(out.stdout)\n",
    "    \n",
    "    if out.stderr: print(out.stderr)\n",
    "    if return_stdout: return out.stdout.decode('ascii').strip().split('\\n')\n",
    "    return out\n",
    "\n",
    "def qsub(call: str, queue = 'condo' ,walltime = 3, ppn = 1, out = 'log/', err = 'logerr/' , project_dir = ''):\n",
    "    err_path = f'{project_dir}{err}$PBS_JOBNAME.err'\n",
    "    out_path = f'{project_dir}{out}$PBS_JOBNAME.out'\n",
    "    call_path = f'{project_dir}{call}'\n",
    "    return bash(f'qsub -q {queue} -l nodes=1:ppn={ppn} -j oe -o {out_path} -e {err_path} -l walltime={walltime}:00:00 {call_path}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab16cc45-3e73-4e4d-9fef-2eebfa182c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_3444/1572636344.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\thiag\\AppData\\Local\\Temp/ipykernel_3444/1572636344.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    all_genotypes: str = '/projects/ps-palmer/apurva/riptide/genotypes/round9_1'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class gwas_pipe:\n",
    "    def __init__(self, \n",
    "                 path: str = f'{Path().absolute()}/', \n",
    "                 use_tscc_modules: list = [],\n",
    "                 all_genotypes: str = '/projects/ps-palmer/apurva/riptide/genotypes/round9_1',\n",
    "                 gtca_path: str = '',\n",
    "                 data: pd.DataFrame() = pd.DataFrame(),\n",
    "                 traits: list = [],\n",
    "                 threads: int = 12):\n",
    "        \n",
    "        if use_tscc_modules: bash(f'module load {\" \".join(use_tscc_modules)}')\n",
    "        self.gtca = 'gcta64' if not gtca_path else gtca_path\n",
    "        self.path = path\n",
    "        self.all_genotypes = all_genotypes\n",
    "        df = data\n",
    "        df.columns = df.columns.str.lower()\n",
    "        self.df = df\n",
    "        self.traits = [x.lower() for x in traits]\n",
    "        \n",
    "        self.sample_path = f'{self.path}genotypes/sample_rfids.txt'\n",
    "        self.genotypes_subset = f'{self.path}genotypes/genotypes'\n",
    "        self.genotypes_subset_vcf = f'{self.path}genotypes/genotypes_subset_vcf.vcf.gz'\n",
    "        \n",
    "        self.autoGRM = f'{self.path}grm/AllchrGRM'\n",
    "        self.xGRM = f'{path}grm/xchrGRM'\n",
    "        self.log = pd.DataFrame( columns = ['function', 'call', 'out'])\n",
    "        self.thrflag = f'--thread-num {threads}'\n",
    "        self.print_call = True\n",
    "        \n",
    "        \n",
    "    def bashLog(self, call, func, print_call = True):\n",
    "        self.append2log(func, call , bash(re.sub(r' +', ' ', call), print_call = print_call))\n",
    "        \n",
    "        \n",
    "    def append2log(self, func, call, out):\n",
    "        self.log.loc[len(self.log)] = [func, call, out]\n",
    "        with open(f'{self.path}/log/{func}.log', 'w') as f:\n",
    "            f.write('\\n'.join(out))\n",
    "            \n",
    "    def make_dir_structure(self,folders: list = ['data', 'genotypes', 'grm', 'log', 'logerr' , \n",
    "                                            'results', 'temp', 'data/pheno', 'results/heritability', \n",
    "                                             'results/gwas',  'results/loco', 'results/qtls', 'temp/r2']):\n",
    "        for folder in folders:\n",
    "            os.makedirs(f'{self.path}{folder}', exist_ok = True)\n",
    "            \n",
    "            \n",
    "    def subsetSamplesFromAllGenotypes(self,samplelist: list = [], \n",
    "                                      use_rfid_from_df = True, sourceFormat = 'vcf', \n",
    "                                      geno: float = .1, maf: float = .005, hwe: float = 1e-10 ):\n",
    "        \n",
    "        funcName = inspect.getframeinfo(inspect.currentframe()).function\n",
    "        \n",
    "        os.makedirs(f'{self.path}genotypes', exist_ok = True)\n",
    "        \n",
    "        df = self.df[['rfid', 'rfid']] if use_rfid_from_df else pd.DataFrame([samplelist,samplelist]).T.astype(str)\n",
    "        df.to_csv(f'{self.path}genotypes/sample_rfids.txt', index = False, header = None, sep = ' ')\n",
    "        self.sample_names = samplelist\n",
    "        \n",
    "        fmt_call = {'vcf': 'vcf', 'plink': 'bfile'}[sourceFormat]        \n",
    "        \n",
    "        extra_params = f'--geno {geno} --maf {maf} --hwe {hwe} --double-id --set-missing-var-ids @:#'\n",
    "        \n",
    "        self.bashLog(f'plink --{fmt_call} {self.all_genotypes} --keep {self.sample_path} {extra_params} {self.thrflag} --make-bed --out {self.genotypes_subset}',\n",
    "                    funcName)\n",
    "        \n",
    "    def SubsampleMissMafHweFilter(self, sexfmt: str = 'M|F',  sexColumn: str = 'sex',  \n",
    "                                  geno: float = .1, maf: float = .005, hwe: float = 1e-10,\n",
    "                                  sourceFormat = 'vcf', remove_dup: bool = True, print_call: bool = False):\n",
    "        funcName = inspect.getframeinfo(inspect.currentframe()).function\n",
    "        \n",
    "               \n",
    "        fmt_call = {'vcf': 'vcf', 'plink': 'bfile'}[sourceFormat]  \n",
    "        rmv = f' --double-id --set-missing-var-ids @:# ' if remove_dup else ' '\n",
    "        sub = self.genotypes_subset\n",
    "        \n",
    "        mfList = sorted(sexfmt.split('|'))\n",
    "        self.samples = {}\n",
    "        for num, sx in enumerate(tqdm(mfList)): \n",
    "            \n",
    "            dff = self.df[(self.df[sexColumn] == sx) & \n",
    "                          (self.df.astype(str).rfid.isin(vcftools.get_vcf_header(self.all_genotypes)))]\n",
    "            dff[['rfid', 'rfid']].to_csv(f'{self.path}genotypes/sample_rfids_{sx}.txt', index = False, header = None, sep = ' ')\n",
    "            self.samples[sx] = f'{self.path}genotypes/sample_rfids_{sx}.txt'\n",
    "            \n",
    "            filtering_flags = f' --geno {geno} --maf {maf} --hwe {hwe}'\n",
    "            filtering_flags_justx = f''\n",
    "            extra_flags = f'--not-chr X'  if num == 1 else ''\n",
    "            \n",
    "            self.bashLog(f'plink --{fmt_call} {self.all_genotypes} --keep {self.samples[sx]} {filtering_flags} {rmv} {extra_flags} {self.thrflag} --make-bed --out {sub}_{sx}',\n",
    "                        f'{funcName}_subseting_{sx}')\n",
    "            \n",
    "            \n",
    "            if num == 1:\n",
    "                self.bashLog(f'plink --bfile {sub}_{sx} --chr x {self.thrflag} --make-bed --out {sub}_{sx}_xchr',\n",
    "                        f'{funcName}_maleXsubset{sx}') #--out {sub}_{sx}_xchr\n",
    "                male_1_x_filenames = [aa for aa in [f'{sub}_{sx}', f'{sub}_{sx}_xchr'] if len(glob(aa+'.*')) >= 5]\n",
    "                male_gen_filenames = f'{self.path}/genotypes/temp_male_filenames'\n",
    "                pd.DataFrame(male_1_x_filenames).to_csv(male_gen_filenames, index = False, header = None)\n",
    "            else: female_hwe = f'{sub}_{sx}'\n",
    "                \n",
    "        print('merging sexes')        \n",
    "        self.bashLog(f'plink --bfile {female_hwe} --merge-list {male_gen_filenames} {self.thrflag} {filtering_flags} --make-bed --out {sub}_hwe',\n",
    "                        f'{funcName}_mergeSexes')\n",
    "        \n",
    "        self.genotypes_subset = f'{sub}_hwe'\n",
    "        \n",
    "        #print('geno maf filtering')\n",
    "        #self.bashLog(f'plink --bfile {sub}_hwe --geno {geno} --maf {maf} --thread-num 12 --make-bed --out {sub}',\n",
    "        #                f'{funcName}_geno_maf')\n",
    "        \n",
    "        ### LD pruning \n",
    "        #self.bashLog(f'plink --bfile {sub} --indep-pairwise 50 5 0.999 --thread-num 12 --out {sub}_pruned_50_5_999',\n",
    "        #                f'{funcName}_findLDs')\n",
    "        \n",
    "        #self.bashLog(f'plink --bfile {sub}_hwe --geno {geno} --maf {maf} --thread-num 12 --make-bed --out {sub}_pruned',\n",
    "        #                f'{funcName}_prune')\n",
    "        \n",
    "        \n",
    "    \n",
    "    def generateGRM(self, autosome_list: list = list(range(1,21)), print_call: bool = False,\n",
    "                    extra_chrs: list = ['xchr']):\n",
    "        \n",
    "        funcName = inspect.getframeinfo(inspect.currentframe()).function\n",
    "                \n",
    "        self.bashLog(f'{self.gtca} {self.thrflag} --bfile {self.genotypes_subset} --autosome-num 21 --autosome --make-grm-bin --out {self.autoGRM}',\n",
    "            funcName, print_call = print_call)\n",
    "        \n",
    "        if 'xchr' in extra_chrs:\n",
    "            self.bashLog(f'{self.gtca} {self.thrflag} --bfile {self.genotypes_subset} --make-grm-xchr --out {self.xGRM}',\n",
    "                        f'{funcName}_chrX', print_call = print_call)\n",
    "        \n",
    "        for c in tqdm(autosome_list):\n",
    "            self.bashLog(f'{self.gtca} {self.thrflag} --bfile {self.genotypes_subset} --chr {c} --make-grm-bin --out {self.path}grm/{c}chrGRM',\n",
    "                        f'{funcName}_chr{c}',  print_call = print_call)\n",
    "\n",
    "    def snpHeritability(self, print_call: bool = False):\n",
    "        h2table = pd.DataFrame()\n",
    "        for trait in tqdm(self.traits):\n",
    "            trait_file = f'{self.path}data/pheno/{trait}.txt'\n",
    "            out_file = f'{self.path}results/heritability/{trait}' \n",
    "            df.dropna(subset = ['rfid'])[['rfid', 'rfid', trait]].fillna('NA').astype(str).to_csv(trait_file, index = False, sep = ' ', header = None)\n",
    "            \n",
    "            self.bashLog(f'{self.gtca} --reml {self.thrflag} --pheno {trait_file} --grm {self.autoGRM} --out {out_file}',\n",
    "                        f'snpHeritability_{trait}', print_call = print_call)\n",
    "            \n",
    "            a = pd.read_csv(f'{out_file}.hsq', skipfooter=6, sep = '\\t',engine='python')\n",
    "            b = pd.read_csv(f'{out_file}.hsq', skiprows=6, sep = '\\t', header = None, index_col = 0).T.rename({1: trait})\n",
    "            newrow = pd.concat(\n",
    "                [a[['Source','Variance']].T[1:].rename({i:j for i,j in enumerate(a.Source)}, axis = 1).rename({'Variance': trait}),\n",
    "                b],axis =1 )\n",
    "            h2table= pd.concat([h2table,newrow])\n",
    "            \n",
    "        h2table.to_csv(f'{self.path}results/heritability/heritability.tsv', sep = '\\t')\n",
    "        return h2table\n",
    "        \n",
    "    def gwasPerChr(self, nchr: int = 21, print_call: bool = False):\n",
    "        for trait, chrom in tqdm(list(itertools.product(gwas.traits, range(1,nchr+1)))):\n",
    "            if chrom == 21: chrom = 'x'\n",
    "            self.bashLog(f'{self.gtca} {self.thrflag} --pheno {self.path}data/pheno/{trait}.txt --bfile {self.genotypes_subset} \\\n",
    "                                       --grm {self.path}grm/AllchrGRM   \\\n",
    "                                       --chr {chrom} \\\n",
    "                                       --mlma-subtract-grm {self.path}grm/{chrom}chrGRM  \\\n",
    "                                       --mlma --out {self.path}results/gwas/gwas_{chrom}_{trait}',\n",
    "                        f'GWAS_{chrom}_{trait}', print_call = print_call)\n",
    "    \n",
    "    def GWAS(self, subtract_grm: bool = False, loco: bool = True , print_call: bool = True):\n",
    "        grm_flag = f'--grm {self.path}grm/AllchrGRM --mlma-subtract-grm {self.path}grm/AllchrGRM' if subtract_grm else ''\n",
    "        grm_name = 'sub_grm' if subtract_grm else 'with_grm'\n",
    "        loco_flag = '-loco' if loco else ''\n",
    "        for trait in tqdm(self.traits):\n",
    "            self.bashLog(f'{self.gtca} {self.thrflag} --pheno {self.path}data/pheno/{trait}.txt --bfile {self.genotypes_subset}\\\n",
    "                                       {grm_flag}  \\\n",
    "                                       --mlma{loco_flag} --out {self.path}results/loco/{trait}',\n",
    "                        f'GWAS_{grm_name}_{loco_flag[1:]}_{trait}',  print_call = print_call)\n",
    "        \n",
    "    def callQTLs(self, threshold: float = 5.3, window: int = 1e6, subterm: int = 2,\n",
    "                 ldwin = 1e6, ldkb = 11000, ldr2 = .4, qtl_dist = 2*1e6):\n",
    "        \n",
    "        topSNPs = pd.concat([\\\n",
    "             pd.read_csv(f'{self.path}results/gwas/*{t}*.mlma').query(f'p < 1e-{thresh}').assign(trait=t)\\\n",
    "             for t in tqdm(self.traits) ])\n",
    "\n",
    "        out = pd.DataFrame()\n",
    "\n",
    "        for (t, c), df in tqdm(topSNPs.groupby(['trait','Chr'])):\n",
    "            df = df.set_index('bp')\n",
    "            df.p = -np.log10(df.p)\n",
    "\n",
    "            while df.query('p > @threshold').shape[0]:\n",
    "                idx = df.p.idxmax()\n",
    "                maxp = df.loc[idx]\n",
    "                correlated_snps = df.loc[idx- window//2: idx + window//2].query('p > @maxp.p - @subterm')\n",
    "                qtl = True if correlated_snps.shape[0] > 2 else False\n",
    "\n",
    "                out = pd.concat([out,\n",
    "                                 maxp.to_frame().T.assign(QTL= qtl)],\n",
    "                                 axis = 0)\n",
    "\n",
    "                ldfilename = f'{self.path}temp/r2/temp_qtl_n_{t}'\n",
    "                self.bashLog(f'plink --bfile {self.genotypes_subset} --chr {c}  --ld-snp {maxp.SNP} \\\n",
    "                                     --ld-window {ldwin} {self.thrflag} \\\n",
    "                                     --nonfounders --r2  \\\n",
    "                                     --ld-window-r2 {ldr2} --out {ldfilename}',\n",
    "                             f'qlt_{t}', False )#--ld_window_kb {ldkb}\n",
    "\n",
    "                try: \n",
    "                    ldSNPS = pd.read_csv(f'{ldfilename}.ld', sep = r'\\s+').SNP_B.to_list() + [maxp.SNP]\n",
    "                    df = df.query('~(@idx - @qtl_dist//2 < index < @idx + @qtl_dist//2) and (SNP not in @ldSNPS)')\n",
    "                except:\n",
    "                    ldSNPS = [maxp.SNP]\n",
    "                    df = df.query('(SNP not in @ldSNPS)')\n",
    "                #if sum(cnt.values()) % 10 == 0: print(cnt)\n",
    "\n",
    "        out =  out.reset_index().rename({'index': 'bp'}, axis = 1).sort_values('trait')\n",
    "        out.to_csv(f'{self.path}/qtls/allQTLS.csv', index = False)\n",
    "        return out            \n",
    "\n",
    "    def annSnpEff(self):\n",
    "        pass \n",
    "                \n",
    "\n",
    "    def print_watermark():\n",
    "        pass\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea75aa6f-bd4a-4766-b730-ca379b52de7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logL0</th>\n",
       "      <th>LRT</th>\n",
       "      <th>df</th>\n",
       "      <th>Pval</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-104.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        logL0  LRT   df  Pval      n\n",
       "trait -104.048  0.0  1.0   0.5  191.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwas = gwas_pipe(path = 'test/',\n",
    "                all_genotypes = '../hsrats_round9_1/Heterogenous-stock_n14780_10182022_QC_Sex_Het_pass_n13548.vcf.gz',\n",
    "                data = df,\n",
    "                traits =  df.loc[:, 'runwayhandler':].columns.tolist())\n",
    "\n",
    "gwas.make_dir_structure()\n",
    "%time gwas.SubsampleMissMafHweFilter()\n",
    "%time gwas.generateGRM()\n",
    "%time gwas.snpHeritability()\n",
    "%time gwas.gwasPerChr()\n",
    "%time gwas.GWAS()\n",
    "%time gwas.callQTLs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "32c69587-4d34-4193-a292-a328f4f6bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logL0</th>\n",
       "      <th>LRT</th>\n",
       "      <th>df</th>\n",
       "      <th>Pval</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-104.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-104.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-104.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-104.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        logL0  LRT   df  Pval      n\n",
       "trait -104.048  0.0  1.0   0.5  191.0\n",
       "trait -104.048  0.0  1.0   0.5  191.0\n",
       "trait -104.048  0.0  1.0   0.5  191.0\n",
       "trait -104.048  0.0  1.0   0.5  191.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2table = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    h2table = h2table.append(b)\n",
    "h2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b949cbd-3678-48f3-9ffd-d1de8b36c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplelist = ['a', 'b', 'c']\n",
    "df = pd.DataFrame([samplelist,samplelist]).T\n",
    "#df.to_csv('genotypes/sample_rfids.txt', index = False, header = None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a0e9ff-8c12-45f7-b0da-77ba9b95b00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\thiag\\\\Documents\\\\GitHub\\\\GWAS_pipeline\\\\gwas_python_code'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf91337-35c7-4f81-a509-102bdd63a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if []: print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522463a4-5629-445e-a838-35960293690c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CoViewer]",
   "language": "python",
   "name": "conda-env-CoViewer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
